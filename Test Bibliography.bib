
@article{carton_extractive_2018,
	title = {Extractive {Adversarial} {Networks}: {High}-{Recall} {Explanations} for {Identifying} {Personal} {Attacks} in {Social} {Media} {Posts}},
	shorttitle = {Extractive {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1809.01499},
	abstract = {We introduce an adversarial method for producing high-recall explanations of neural text classifier decisions. Building on an existing architecture for extractive explanations via hard attention, we add an adversarial layer which scans the residual of the attention for remaining predictive signal. Motivated by the important domain of detecting personal attacks in social media comments, we additionally demonstrate the importance of manually setting a semantically appropriate `default' behavior for the model by explicitly manipulating its bias term. We develop a validation set of human-annotated personal attacks to evaluate the impact of these changes.},
	urldate = {2019-03-18},
	journal = {arXiv:1809.01499 [cs, stat]},
	author = {Carton, Samuel and Mei, Qiaozhu and Resnick, Paul},
	month = aug,
	year = {2018},
	note = {arXiv: 1809.01499},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Accepted to EMNLP 2018 Code and data available at https://github.com/shcarton/rcnn},
	file = {arXiv\:1809.01499 PDF:C\:\\Users\\Hamza\\Zotero\\storage\\VJ2QY72W\\Carton et al. - 2018 - Extractive Adversarial Networks High-Recall Expla.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Hamza\\Zotero\\storage\\YJP3VZF8\\1809.html:text/html}
}